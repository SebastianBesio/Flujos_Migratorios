{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"ethereal-accord-397414-944cb605214b.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creción de Tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_tabla(dataset_id, table_id, schema):\n",
    "    \"\"\"\n",
    "    Funcion que crea una tabla en el dataset con el schema pasado.\n",
    "    \"\"\"\n",
    "    client = bigquery.Client()\n",
    "    # Preparar estructura de la tabla.\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    table = bigquery.Table(table_ref, schema=schema)\n",
    "\n",
    "    # Envía la solicitud para crear la tabla.\n",
    "    client.create_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir nombre del Dataset\n",
    "dataset_id = \"Migraciones\"\n",
    "project_id = \"ethereal-accord-397414\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "File ethereal-accord-397414-944cb605214b.json was not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      2\u001b[0m table_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpais\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m schema \u001b[39m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m     bigquery\u001b[39m.\u001b[39mSchemaField(\u001b[39m\"\u001b[39m\u001b[39mid_pais\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mINTEGER\u001b[39m\u001b[39m\"\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNULLABLE\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m      6\u001b[0m     bigquery\u001b[39m.\u001b[39mSchemaField(\u001b[39m\"\u001b[39m\u001b[39mnombre\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSTRING\u001b[39m\u001b[39m\"\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNULLABLE\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m ]\n\u001b[1;32m----> 9\u001b[0m crear_tabla(dataset_id, table_id, schema)\n",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m, in \u001b[0;36mcrear_tabla\u001b[1;34m(dataset_id, table_id, schema)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcrear_tabla\u001b[39m(dataset_id, table_id, schema):\n\u001b[0;32m      2\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m    Funcion que crea una tabla en el dataset con el schema pasado.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     client \u001b[39m=\u001b[39m bigquery\u001b[39m.\u001b[39;49mClient()\n\u001b[0;32m      6\u001b[0m     \u001b[39m# Preparar estructura de la tabla.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     table_ref \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mdataset(dataset_id)\u001b[39m.\u001b[39mtable(table_id)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\cloud\\bigquery\\client.py:245\u001b[0m, in \u001b[0;36mClient.__init__\u001b[1;34m(self, project, credentials, _http, location, default_query_job_config, default_load_job_config, client_info, client_options)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    235\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    236\u001b[0m     project\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    243\u001b[0m     client_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    244\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 245\u001b[0m     \u001b[39msuper\u001b[39;49m(Client, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    246\u001b[0m         project\u001b[39m=\u001b[39;49mproject,\n\u001b[0;32m    247\u001b[0m         credentials\u001b[39m=\u001b[39;49mcredentials,\n\u001b[0;32m    248\u001b[0m         client_options\u001b[39m=\u001b[39;49mclient_options,\n\u001b[0;32m    249\u001b[0m         _http\u001b[39m=\u001b[39;49m_http,\n\u001b[0;32m    250\u001b[0m     )\n\u001b[0;32m    252\u001b[0m     kw_args \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mclient_info\u001b[39m\u001b[39m\"\u001b[39m: client_info}\n\u001b[0;32m    253\u001b[0m     bq_host \u001b[39m=\u001b[39m _get_bigquery_host()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\cloud\\client\\__init__.py:320\u001b[0m, in \u001b[0;36mClientWithProject.__init__\u001b[1;34m(self, project, credentials, client_options, _http)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, project\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, credentials\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, client_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, _http\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 320\u001b[0m     _ClientProjectMixin\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, project\u001b[39m=\u001b[39;49mproject, credentials\u001b[39m=\u001b[39;49mcredentials)\n\u001b[0;32m    321\u001b[0m     Client\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m    322\u001b[0m         \u001b[39mself\u001b[39m, credentials\u001b[39m=\u001b[39mcredentials, client_options\u001b[39m=\u001b[39mclient_options, _http\u001b[39m=\u001b[39m_http\n\u001b[0;32m    323\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\cloud\\client\\__init__.py:268\u001b[0m, in \u001b[0;36m_ClientProjectMixin.__init__\u001b[1;34m(self, project, credentials)\u001b[0m\n\u001b[0;32m    265\u001b[0m     project \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(credentials, \u001b[39m\"\u001b[39m\u001b[39mproject_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    267\u001b[0m \u001b[39mif\u001b[39;00m project \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 268\u001b[0m     project \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_determine_default(project)\n\u001b[0;32m    270\u001b[0m \u001b[39mif\u001b[39;00m project \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    272\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mProject was not passed and could not be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdetermined from the environment.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\cloud\\client\\__init__.py:287\u001b[0m, in \u001b[0;36m_ClientProjectMixin._determine_default\u001b[1;34m(project)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    285\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_determine_default\u001b[39m(project):\n\u001b[0;32m    286\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Helper:  use default project detection.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     \u001b[39mreturn\u001b[39;00m _determine_default_project(project)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\cloud\\_helpers\\__init__.py:152\u001b[0m, in \u001b[0;36m_determine_default_project\u001b[1;34m(project)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Determine default project ID explicitly or implicitly as fall-back.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \n\u001b[0;32m    142\u001b[0m \u001b[39mSee :func:`google.auth.default` for details on how the default project\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[39m:returns: Default project if it can be determined.\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[39mif\u001b[39;00m project \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 152\u001b[0m     _, project \u001b[39m=\u001b[39m google\u001b[39m.\u001b[39;49mauth\u001b[39m.\u001b[39;49mdefault()\n\u001b[0;32m    153\u001b[0m \u001b[39mreturn\u001b[39;00m project\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\auth\\_default.py:659\u001b[0m, in \u001b[0;36mdefault\u001b[1;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[0;32m    647\u001b[0m checkers \u001b[39m=\u001b[39m (\n\u001b[0;32m    648\u001b[0m     \u001b[39m# Avoid passing scopes here to prevent passing scopes to user credentials.\u001b[39;00m\n\u001b[0;32m    649\u001b[0m     \u001b[39m# with_scopes_if_required() below will ensure scopes/default scopes are\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[39mlambda\u001b[39;00m: _get_gce_credentials(request, quota_project_id\u001b[39m=\u001b[39mquota_project_id),\n\u001b[0;32m    656\u001b[0m )\n\u001b[0;32m    658\u001b[0m \u001b[39mfor\u001b[39;00m checker \u001b[39min\u001b[39;00m checkers:\n\u001b[1;32m--> 659\u001b[0m     credentials, project_id \u001b[39m=\u001b[39m checker()\n\u001b[0;32m    660\u001b[0m     \u001b[39mif\u001b[39;00m credentials \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m         credentials \u001b[39m=\u001b[39m with_scopes_if_required(\n\u001b[0;32m    662\u001b[0m             credentials, scopes, default_scopes\u001b[39m=\u001b[39mdefault_scopes\n\u001b[0;32m    663\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\auth\\_default.py:652\u001b[0m, in \u001b[0;36mdefault.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauth\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcredentials\u001b[39;00m \u001b[39mimport\u001b[39;00m CredentialsWithQuotaProject\n\u001b[0;32m    643\u001b[0m explicit_project_id \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\n\u001b[0;32m    644\u001b[0m     environment_vars\u001b[39m.\u001b[39mPROJECT, os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(environment_vars\u001b[39m.\u001b[39mLEGACY_PROJECT)\n\u001b[0;32m    645\u001b[0m )\n\u001b[0;32m    647\u001b[0m checkers \u001b[39m=\u001b[39m (\n\u001b[0;32m    648\u001b[0m     \u001b[39m# Avoid passing scopes here to prevent passing scopes to user credentials.\u001b[39;00m\n\u001b[0;32m    649\u001b[0m     \u001b[39m# with_scopes_if_required() below will ensure scopes/default scopes are\u001b[39;00m\n\u001b[0;32m    650\u001b[0m     \u001b[39m# safely set on the returned credentials since requires_scopes will\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[39m# guard against setting scopes on user credentials.\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m     \u001b[39mlambda\u001b[39;00m: _get_explicit_environ_credentials(quota_project_id\u001b[39m=\u001b[39;49mquota_project_id),\n\u001b[0;32m    653\u001b[0m     \u001b[39mlambda\u001b[39;00m: _get_gcloud_sdk_credentials(quota_project_id\u001b[39m=\u001b[39mquota_project_id),\n\u001b[0;32m    654\u001b[0m     _get_gae_credentials,\n\u001b[0;32m    655\u001b[0m     \u001b[39mlambda\u001b[39;00m: _get_gce_credentials(request, quota_project_id\u001b[39m=\u001b[39mquota_project_id),\n\u001b[0;32m    656\u001b[0m )\n\u001b[0;32m    658\u001b[0m \u001b[39mfor\u001b[39;00m checker \u001b[39min\u001b[39;00m checkers:\n\u001b[0;32m    659\u001b[0m     credentials, project_id \u001b[39m=\u001b[39m checker()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\auth\\_default.py:272\u001b[0m, in \u001b[0;36m_get_explicit_environ_credentials\u001b[1;34m(quota_project_id)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_gcloud_sdk_credentials(quota_project_id\u001b[39m=\u001b[39mquota_project_id)\n\u001b[0;32m    271\u001b[0m \u001b[39mif\u001b[39;00m explicit_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m     credentials, project_id \u001b[39m=\u001b[39m load_credentials_from_file(\n\u001b[0;32m    273\u001b[0m         os\u001b[39m.\u001b[39;49menviron[environment_vars\u001b[39m.\u001b[39;49mCREDENTIALS], quota_project_id\u001b[39m=\u001b[39;49mquota_project_id\n\u001b[0;32m    274\u001b[0m     )\n\u001b[0;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m credentials, project_id\n\u001b[0;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\auth\\_default.py:116\u001b[0m, in \u001b[0;36mload_credentials_from_file\u001b[1;34m(filename, scopes, default_scopes, quota_project_id, request)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Loads Google credentials from a file.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \n\u001b[0;32m     86\u001b[0m \u001b[39mThe credentials file must be a service account key, stored authorized\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39m        wrong format or is missing.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(filename):\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mDefaultCredentialsError(\n\u001b[0;32m    117\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m was not found.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(filename)\n\u001b[0;32m    118\u001b[0m     )\n\u001b[0;32m    120\u001b[0m \u001b[39mwith\u001b[39;00m io\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file_obj:\n\u001b[0;32m    121\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m: File ethereal-accord-397414-944cb605214b.json was not found."
     ]
    }
   ],
   "source": [
    "# Crear tabla 'pais'\n",
    "table_id = \"pais\"\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"id_pais\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"nombre\", \"STRING\", mode=\"NULLABLE\")\n",
    "]\n",
    "\n",
    "crear_tabla(dataset_id, table_id, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla 'fac_social'\n",
    "table_id = \"fac_social\"\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"id_fac_soc\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"hdi\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"anio_prom_esc\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"esperanza_vida\", \"FLOAT\", mode=\"NULLABLE\")\n",
    "]\n",
    "\n",
    "crear_tabla(dataset_id, table_id, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla 'inmigracion'\n",
    "table_id = \"inmigracion\"\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"id_inmigracion\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"hombres\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"mujeres\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"total\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Argentina\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Antigua_y_Barbuda\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Bahamas\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Belice\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Bolivia\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Brasil\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Canada\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Chile\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Colombia\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Costa_Rica\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Cuba\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Santa_Lucia\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Ecuador\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Granada\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Guatemala\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Guyana\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Honduras\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Haiti\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Jamaica\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Republica_Dominicana\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Mexico\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Nicaragua\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Panama\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Peru\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Paraguay\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"El_Salvador\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Trinidad_y_Tobago\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Uruguay\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Estados_Unidos\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Venezuela\", \"INTEGER\", mode=\"NULLABLE\")\n",
    "]\n",
    "\n",
    "crear_tabla(dataset_id, table_id, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla 'fac_economico'\n",
    "table_id = \"fac_economico\"\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"id_fac_eco\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"pbi_per_capita\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"pbi_per_cap_aj\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"desempleo\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "]\n",
    "\n",
    "crear_tabla(dataset_id, table_id, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla 'migracion'\n",
    "table_id = \"migracion\"\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"id_migracion\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"id_inmigracion\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"id_fac_soc\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"id_fac_eco\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"id_pais\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"migracion_neta\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"anio\", \"DATE\", mode=\"NULLABLE\")\n",
    "]\n",
    "\n",
    "crear_tabla(dataset_id, table_id, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################\n",
    "# Generacion Data Frames preparados para BigQuery  y guardado CSV respaldo en el Cloud Storage\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder_name = \"ArchivosFuente/\"\n",
    "bq_folder_name = \"ParaBigQuery/\"\n",
    "bucket_name = 'bucket-pf-flujos_migratorios'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lectura_csv_bucket(file_path, bucket_name):\n",
    "    \"\"\" \n",
    "    Lectura de un csv en file_path desde el Bucket bucket_name.\n",
    "    Retorna un DataFrame con el csv leido.\n",
    "    \"\"\"\n",
    "    # Crea un cliente de almacenamiento de Google Cloud\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Obtiene el cubo de almacenamiento\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    # Obtiene el objeto de archivo CSV\n",
    "    blob = bucket.blob(file_path)\n",
    "\n",
    "    # Lee el contenido del archivo CSV en un DataFrame de Pandas\n",
    "    with blob.open(\"r\") as file:\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def guardado_csv_bucket(df, file_path, bucket_name):\n",
    "    \"\"\" \n",
    "    Guardado de un DataFrame en csv en file_path desde el Bucket bucket_name.\n",
    "    \"\"\"\n",
    "    # Guarda el DataFrame en un archivo CSV\n",
    "    csv_data = df.to_csv(index=False)\n",
    "\n",
    "    # Crea un cliente de almacenamiento de Google Cloud\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Obtiene el cubo de almacenamiento\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    # Carga el archivo CSV en el bucket de Google Cloud Storage\n",
    "    blob = bucket.blob(file_path)\n",
    "    blob.upload_from_string(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de todos los csv fuentes desde el Bucket.\n",
    "file_path_undp = source_folder_name + 'migracion_undp.csv'\n",
    "df_undp = lectura_csv_bucket(file_path_undp, bucket_name)\n",
    "file_path_bm = source_folder_name + 'migracion_desempleo_pbi_per_capita.csv'\n",
    "df_bm = lectura_csv_bucket(file_path_bm, bucket_name)\n",
    "file_path_inmigracion = source_folder_name + 'Inmigracion_por_pais.csv'\n",
    "df_inmigracion = lectura_csv_bucket(file_path_inmigracion, bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Generacion DF y CSV para tabla 'pais'\n",
    "######################################\n",
    "\n",
    "# Generador de 'id_pais'\n",
    "pais = []\n",
    "j = 1\n",
    "for i in (df_undp['Pais'].unique()):\n",
    "    pais.append([j,i])\n",
    "    j += 1\n",
    "\n",
    "df_bq_pais = pd.DataFrame(pais, columns = ['id_pais','nombre'])\n",
    "\n",
    "# Guardo CSV\n",
    "file_path = bq_folder_name + 'pais.csv'\n",
    "guardado_csv_bucket(df_bq_pais, file_path, bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Generacion DF y CSV para tabla 'fac_social'\n",
    "######################################\n",
    "\n",
    "# Como son todos del mismo Dataset no necesitamos hacer un merge.\n",
    "df_bq_fac_soc = df_undp.copy()\n",
    "df_bq_fac_soc['id_pais'] = df_undp['Pais'].replace(dict(zip(df_bq_pais[\"nombre\"], df_bq_pais[\"id_pais\"])))\n",
    "df_bq_fac_soc['id_fac_soc'] = 10000 * df_bq_fac_soc['Anio'] + df_bq_fac_soc['id_pais']\n",
    "\n",
    "df_bq_fac_soc.drop(columns=['Pais', 'id_pais', 'Anio', 'PBI_per_cap_aj'], inplace=True)\n",
    "\n",
    "df_bq_fac_soc.head()\n",
    "\n",
    "# Guardo CSV\n",
    "file_path = bq_folder_name + 'fac_social.csv'\n",
    "guardado_csv_bucket(df_bq_fac_soc, file_path, bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Generacion DF y CSV para tabla 'fac_economico'\n",
    "######################################\n",
    "\n",
    "df_bq_fac_eco = df_undp.merge(df_bm, on=['Pais', 'Anio'])\n",
    "\n",
    "df_bq_fac_eco['id_pais'] = df_bq_fac_eco['Pais'].replace(dict(zip(df_bq_pais[\"nombre\"], df_bq_pais[\"id_pais\"])))\n",
    "df_bq_fac_eco['id_fac_eco'] = 10000 * df_bq_fac_eco['Anio'] + df_bq_fac_eco['id_pais']\n",
    "\n",
    "df_bq_fac_eco.drop(columns=['Pais', 'id_pais', 'Anio', 'hdi', 'Esperanza_vida', 'Anio_prom_esc', 'migracion_neta'], inplace=True)\n",
    "\n",
    "df_bq_fac_eco.rename(columns={'PBI_per_cap_aj': 'pbi_per_cap_aj'}, inplace=True)\n",
    "\n",
    "# Guardo CSV\n",
    "file_path = bq_folder_name + 'fac_economico.csv'\n",
    "guardado_csv_bucket(df_bq_fac_eco, file_path, bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Generacion DF y CSV para tabla 'inmigracion'\n",
    "######################################\n",
    "\n",
    "df_bq_inmigracion = df_inmigracion.copy()\n",
    "df_bq_inmigracion['id_pais'] = df_bq_inmigracion['Pais'].replace(dict(zip(df_bq_pais[\"nombre\"], df_bq_pais[\"id_pais\"])))\n",
    "df_bq_inmigracion['id_inmigracion'] = 10000 * df_bq_inmigracion['Anio'] + df_bq_inmigracion['id_pais']\n",
    "\n",
    "df_bq_inmigracion.drop(columns=['Pais', 'id_pais', 'Anio'], inplace=True)\n",
    "# Renombro asi coinciden\n",
    "df_bq_inmigracion.rename(columns={'Inmigrantes_hombres': 'hombres', 'Inmigrantes_mujeres': 'mujeres', 'Inmigrantes': 'total'}, inplace=True)\n",
    "\n",
    "# Paso a Int\n",
    "df_bq_inmigracion[df_bq_inmigracion.columns] = df_bq_inmigracion[df_bq_inmigracion.columns].astype('Int64')\n",
    "\n",
    "# Guardo CSV\n",
    "file_path = bq_folder_name + 'inmigracion.csv'\n",
    "guardado_csv_bucket(df_bq_inmigracion, file_path, bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Generacion DF y CSV para tabla 'migracion'\n",
    "######################################\n",
    "\n",
    "df_bq_migracion = df_bm.copy()\n",
    "df_bq_migracion['id_pais'] = df_bq_migracion['Pais'].replace(dict(zip(df_bq_pais[\"nombre\"], df_bq_pais[\"id_pais\"])))\n",
    "df_bq_migracion['id_migracion'] = 10000 * df_bq_migracion['Anio'] + df_bq_migracion['id_pais']\n",
    "\n",
    "df_bq_migracion.drop(columns=['Pais', 'desempleo', 'pbi_per_capita'], inplace=True)\n",
    "# Anio con minuscula\n",
    "df_bq_migracion.rename(columns={'Anio': 'anio'}, inplace=True)\n",
    "\n",
    "# crear ids de los otros copiando de id_migracion\n",
    "df_bq_migracion['id_inmigracion'] = df_bq_migracion['id_migracion']\n",
    "df_bq_migracion['id_fac_soc'] = df_bq_migracion['id_migracion']\n",
    "df_bq_migracion['id_fac_eco'] = df_bq_migracion['id_migracion']\n",
    "\n",
    "#Quitar id erroneos\n",
    "df_bq_migracion.loc[~df_bq_migracion['id_migracion'].isin(df_bq_inmigracion['id_inmigracion']), 'id_inmigracion'] = None\n",
    "df_bq_migracion.loc[~df_bq_migracion['id_migracion'].isin(df_bq_fac_soc['id_fac_soc']), 'id_fac_soc'] = None\n",
    "df_bq_migracion.loc[~df_bq_migracion['id_migracion'].isin(df_bq_fac_eco['id_fac_eco']), 'id_fac_eco'] = None\n",
    "\n",
    "# Vuelvo a convertir a Int\n",
    "df_bq_migracion['id_inmigracion'] = df_bq_migracion['id_inmigracion'].astype('Int64')\n",
    "df_bq_migracion['id_fac_soc'] = df_bq_migracion['id_fac_soc'].astype('Int64')\n",
    "df_bq_migracion['id_fac_eco'] = df_bq_migracion['id_fac_eco'].astype('Int64')\n",
    "df_bq_migracion['migracion_neta'] = df_bq_migracion['migracion_neta'].astype('Int64')\n",
    "\n",
    "# Convertir anio a tipo DATE\n",
    "df_bq_migracion['anio'] = df_bq_migracion['anio'].astype(\"string\") + \"-01-01\"\n",
    "df_bq_migracion['anio'] =  pd.to_datetime(df_bq_migracion['anio'], format=\"%Y-%m-%d\")\n",
    "\n",
    "# Guardo CSV\n",
    "file_path = bq_folder_name + 'migracion.csv'\n",
    "guardado_csv_bucket(df_bq_migracion, file_path, bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################################\n",
    "# Pasaje a BigQuery\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carga_tabla_bq(df, dataset_id, table_id, bucket, project_id, primary_key):\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # Define el ID completo de la tabla en BigQuery\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "    # Query existing data from the table\n",
    "    query = f\"SELECT {primary_key} FROM `{project_id}.{dataset_id}.{table_id}`\"\n",
    "    existing_primary_keys = set(row[primary_key] for row in client.query(query))\n",
    "\n",
    "    # Identify unique rows based on primary key\n",
    "    new_rows = df[~df[primary_key].isin(existing_primary_keys)]\n",
    "    \n",
    "    print(new_rows)\n",
    "    \n",
    "    # Load the new rows into BigQuery\n",
    "    if not new_rows.empty:\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            write_disposition=\"WRITE_APPEND\", # Append al final de la tabla\n",
    "            autodetect=True, # Detectar automáticamente el esquema de la tabla\n",
    "        )\n",
    "\n",
    "        job = client.load_table_from_dataframe(new_rows, table_ref, job_config=job_config)\n",
    "        job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "carga_tabla_bq(df_bq_pais, dataset_id, 'pais', bucket_name, project_id, 'id_pais')\n",
    "carga_tabla_bq(df_bq_fac_soc, dataset_id, 'fac_social', bucket_name, project_id, 'id_fac_soc')\n",
    "carga_tabla_bq(df_bq_fac_eco, dataset_id, 'fac_economico', bucket_name, project_id, 'id_fac_eco')\n",
    "carga_tabla_bq(df_bq_inmigracion, dataset_id, 'inmigracion', bucket_name, project_id, 'id_inmigracion')\n",
    "carga_tabla_bq(df_bq_migracion, dataset_id, 'migracion', bucket_name, project_id, 'id_migracion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [anio, migracion_neta, id_pais, id_migracion, id_inmigracion, id_fac_soc, id_fac_eco]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# carga_tabla_bq(df_bq_migracion, dataset_id, 'migracion', bucket_name, project_id, 'id_migracion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install db-dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def carga_tabla_bq(dataset_id, table_id, bucket, project_id, primary_key):\n",
    "\n",
    "#     file_path = bq_folder_name + table_id + '.csv'\n",
    "#     # cloud_storage_uri = f'gs://{bucket}/{file_path}'\n",
    "#     client = bigquery.Client()\n",
    "\n",
    "#     # Define el ID completo de la tabla en BigQuery\n",
    "#     table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "#     # Read the CSV file from GCS\n",
    "#     df = lectura_csv_bucket(file_path, bucket)\n",
    "\n",
    "#     # Query existing data from the table\n",
    "#     query = f\"SELECT {primary_key} FROM `{project_id}.{dataset_id}.{table_id}`\"\n",
    "#     existing_primary_keys = set(row[primary_key] for row in client.query(query))\n",
    "\n",
    "#     # Identify unique rows based on primary key\n",
    "#     new_rows = df[~df[primary_key].isin(existing_primary_keys)]\n",
    "    \n",
    "#     print(new_rows)\n",
    "    \n",
    "#     # Load the new rows into BigQuery\n",
    "#     if not new_rows.empty:\n",
    "#         job_config = bigquery.LoadJobConfig(\n",
    "#             write_disposition=\"WRITE_APPEND\", # Append al final de la tabla\n",
    "#             autodetect=True, # Detectar automáticamente el esquema de la tabla\n",
    "#         )\n",
    "\n",
    "#         job = client.load_table_from_dataframe(new_rows, table_ref, job_config=job_config)\n",
    "#         job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id_pais                nombre\n",
      "0         1             Argentina\n",
      "1         2     Antigua y Barbuda\n",
      "2         3               Bahamas\n",
      "3         4                Belice\n",
      "4         5               Bolivia\n",
      "5         6                Brasil\n",
      "6         7                Canada\n",
      "7         8                 Chile\n",
      "8         9              Colombia\n",
      "9        10            Costa Rica\n",
      "10       11                  Cuba\n",
      "11       12           Santa Lucia\n",
      "12       13               Ecuador\n",
      "13       14               Granada\n",
      "14       15             Guatemala\n",
      "15       16                Guyana\n",
      "16       17              Honduras\n",
      "17       18                 Haiti\n",
      "18       19               Jamaica\n",
      "19       20  Republica Dominicana\n",
      "20       21                Mexico\n",
      "21       22             Nicaragua\n",
      "22       23                Panama\n",
      "23       24                  Peru\n",
      "24       25              Paraguay\n",
      "25       26           El Salvador\n",
      "26       27     Trinidad y Tobago\n",
      "27       28               Uruguay\n",
      "28       29        Estados Unidos\n",
      "29       30             Venezuela\n",
      "False\n",
      "       hdi  Esperanza_vida  Anio_prom_esc  id_fac_soc\n",
      "0    0.723         71.7837       8.126089    19900001\n",
      "1    0.730         72.3190       8.192950    19910001\n",
      "2    0.735         72.4295       8.260361    19920001\n",
      "3    0.739         72.5646       8.327772    19930001\n",
      "4    0.744         73.1725       8.395183    19940001\n",
      "..     ...             ...            ...         ...\n",
      "955  0.744         71.9430      10.570760    20170030\n",
      "956  0.738         71.9788      10.835699    20180030\n",
      "957  0.721         72.1614      11.107277    20190030\n",
      "958  0.695         71.0949      11.107277    20200030\n",
      "959  0.691         70.5536      11.107277    20210030\n",
      "\n",
      "[960 rows x 4 columns]\n",
      "False\n",
      "     pbi_per_cap_aj  desempleo  pbi_per_capita  id_fac_eco\n",
      "0      13597.686360        NaN     4330.967451    19900001\n",
      "1      14803.998880      5.440     5730.723810    19910001\n",
      "2      15940.726020      6.360     6815.331623    19920001\n",
      "3      17132.684480     10.100     6957.417499    19930001\n",
      "4      17874.843990     11.760     7464.474737    19940001\n",
      "..              ...        ...             ...         ...\n",
      "955    12321.887000      5.050             NaN    20170030\n",
      "956    10431.452000      5.020             NaN    20180030\n",
      "957     7045.248000      5.092             NaN    20190030\n",
      "958     4908.065000      7.530             NaN    20200030\n",
      "959     4810.882621      6.471             NaN    20210030\n",
      "\n",
      "[960 rows x 4 columns]\n",
      "False\n",
      "      hombres   mujeres     total  Argentina  Antigua_y_Barbuda  Bahamas   \n",
      "0      788130    861789   1649919        NaN                NaN      NaN  \\\n",
      "1        5775      6254     12029        NaN                NaN      5.0   \n",
      "2       13827     13028     26855        8.0               13.0      NaN   \n",
      "3       16393     14011     30404        NaN                NaN      NaN   \n",
      "4       37549     36209     73758    21923.0               10.0      9.0   \n",
      "..        ...       ...       ...        ...                ...      ...   \n",
      "205     20344     22423     42767      218.0                NaN      NaN   \n",
      "206     39179     39670     78849        NaN                NaN      NaN   \n",
      "207     50937     57330    108267    33022.0                NaN      NaN   \n",
      "208  24478996  26153840  50632836   219448.0            46037.0  46921.0   \n",
      "209    652823    671370   1324193     9374.0                NaN      NaN   \n",
      "\n",
      "      Belice   Bolivia    Brasil    Canada  ...  Nicaragua   Panama      Peru   \n",
      "0       12.0  147234.0   34359.0     796.0  ...      145.0    376.0   16366.0  \\\n",
      "1        8.0       NaN       NaN     218.0  ...        NaN      NaN       NaN   \n",
      "2       31.0       NaN      36.0     730.0  ...        9.0     17.0      43.0   \n",
      "3        NaN       NaN       NaN     542.0  ...        NaN      NaN       NaN   \n",
      "4      991.0       NaN   10558.0    1765.0  ...       66.0     92.0    7138.0   \n",
      "..       ...       ...       ...       ...  ...        ...      ...       ...   \n",
      "205    344.0      53.0     245.0     248.0  ...     7956.0    458.0     237.0   \n",
      "206      NaN       NaN       NaN    1972.0  ...        NaN      NaN       NaN   \n",
      "207      NaN       NaN   14762.0     372.0  ...        NaN      NaN     106.0   \n",
      "208  42970.0   80028.0  517519.0  793897.0  ...   255008.0  99764.0  435868.0   \n",
      "209     18.0    1853.0    5680.0    1070.0  ...     1927.0    828.0   44319.0   \n",
      "\n",
      "     Paraguay  El_Salvador  Trinidad_y_Tobago   Uruguay  Estados_Unidos   \n",
      "0    257243.0        182.0               75.0  136906.0          9992.0  \\\n",
      "1         NaN          NaN              356.0       NaN          1308.0   \n",
      "2         NaN          5.0              278.0       2.0          4247.0   \n",
      "3         NaN       6691.0                NaN       NaN          1901.0   \n",
      "4      1173.0         57.0                4.0     402.0          3078.0   \n",
      "..        ...          ...                ...       ...             ...   \n",
      "205      11.0          NaN                NaN      76.0          5488.0   \n",
      "206       NaN          NaN                NaN       NaN          6439.0   \n",
      "207    1225.0          NaN                NaN       NaN           743.0   \n",
      "208   46170.0    1410659.0           208075.0   50274.0             NaN   \n",
      "209     200.0        956.0             2646.0    4519.0         10598.0   \n",
      "\n",
      "     Venezuela  id_inmigracion  \n",
      "0       1981.0        19900001  \n",
      "1         11.0        19900002  \n",
      "2         16.0        19900003  \n",
      "3          NaN        19900004  \n",
      "4        369.0        19900005  \n",
      "..         ...             ...  \n",
      "205      245.0        20200026  \n",
      "206    24001.0        20200027  \n",
      "207    14908.0        20200028  \n",
      "208   505647.0        20200029  \n",
      "209        NaN        20200030  \n",
      "\n",
      "[210 rows x 34 columns]\n",
      "False\n",
      "           Anio  migracion_neta  id_pais  id_migracion  id_inmigracion   \n",
      "0    1990-01-01         -1145.0        2      19900002      19900002.0  \\\n",
      "1    1991-01-01           223.0        2      19910002             NaN   \n",
      "2    1992-01-01           405.0        2      19920002             NaN   \n",
      "3    1993-01-01           484.0        2      19930002             NaN   \n",
      "4    1994-01-01           513.0        2      19940002             NaN   \n",
      "..          ...             ...      ...           ...             ...   \n",
      "985  2018-01-01      -1356759.0       30      20180030             NaN   \n",
      "986  2019-01-01       -976460.0       30      20190030             NaN   \n",
      "987  2020-01-01       -525142.0       30      20200030      20200030.0   \n",
      "988  2021-01-01       -525116.0       30      20210030             NaN   \n",
      "989  2022-01-01             NaN       30      20220030             NaN   \n",
      "\n",
      "     id_fac_soc  id_fac_eco  \n",
      "0    19900002.0  19900002.0  \n",
      "1    19910002.0  19910002.0  \n",
      "2    19920002.0  19920002.0  \n",
      "3    19930002.0  19930002.0  \n",
      "4    19940002.0  19940002.0  \n",
      "..          ...         ...  \n",
      "985  20180030.0  20180030.0  \n",
      "986  20190030.0  20190030.0  \n",
      "987  20200030.0  20200030.0  \n",
      "988  20210030.0  20210030.0  \n",
      "989         NaN         NaN  \n",
      "\n",
      "[990 rows x 7 columns]\n",
      "False\n"
     ]
    },
    {
     "ename": "BadRequest",
     "evalue": "400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/ethereal-accord-397414/jobs?uploadType=multipart: Provided Schema does not match Table ethereal-accord-397414:Migraciones.migracion. Field anio has changed type from DATE to STRING",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mInvalidResponse\u001b[0m                           Traceback (most recent call last)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\cloud\\bigquery\\client.py:2486\u001b[0m, in \u001b[0;36mClient.load_table_from_file\u001b[1;34m(self, file_obj, destination, rewind, size, num_retries, job_id, job_id_prefix, location, project, job_config, timeout)\u001b[0m\n",
      "\u001b[0;32m   2485\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 2486\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_multipart_upload(\n",
      "\u001b[0;32m   2487\u001b[0m             file_obj, job_resource, size, num_retries, timeout, project\u001b[39m=\u001b[39;49mproject\n",
      "\u001b[0;32m   2488\u001b[0m         )\n",
      "\u001b[0;32m   2489\u001b[0m \u001b[39mexcept\u001b[39;00m resumable_media\u001b[39m.\u001b[39mInvalidResponse \u001b[39mas\u001b[39;00m exc:\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\cloud\\bigquery\\client.py:3053\u001b[0m, in \u001b[0;36mClient._do_multipart_upload\u001b[1;34m(self, stream, metadata, size, num_retries, timeout, project)\u001b[0m\n",
      "\u001b[0;32m   3049\u001b[0m     upload\u001b[39m.\u001b[39m_retry_strategy \u001b[39m=\u001b[39m resumable_media\u001b[39m.\u001b[39mRetryStrategy(\n",
      "\u001b[0;32m   3050\u001b[0m         max_retries\u001b[39m=\u001b[39mnum_retries\n",
      "\u001b[0;32m   3051\u001b[0m     )\n",
      "\u001b[1;32m-> 3053\u001b[0m response \u001b[39m=\u001b[39m upload\u001b[39m.\u001b[39;49mtransmit(\n",
      "\u001b[0;32m   3054\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_http, data, metadata, _GENERIC_CONTENT_TYPE, timeout\u001b[39m=\u001b[39;49mtimeout\n",
      "\u001b[0;32m   3055\u001b[0m )\n",
      "\u001b[0;32m   3057\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\resumable_media\\requests\\upload.py:153\u001b[0m, in \u001b[0;36mMultipartUpload.transmit\u001b[1;34m(self, transport, data, metadata, content_type, timeout)\u001b[0m\n",
      "\u001b[0;32m    151\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;32m--> 153\u001b[0m \u001b[39mreturn\u001b[39;00m _request_helpers\u001b[39m.\u001b[39;49mwait_and_retry(\n",
      "\u001b[0;32m    154\u001b[0m     retriable_request, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_status_code, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_strategy\n",
      "\u001b[0;32m    155\u001b[0m )\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\resumable_media\\requests\\_request_helpers.py:155\u001b[0m, in \u001b[0;36mwait_and_retry\u001b[1;34m(func, get_status_code, retry_strategy)\u001b[0m\n",
      "\u001b[0;32m    154\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 155\u001b[0m     response \u001b[39m=\u001b[39m func()\n",
      "\u001b[0;32m    156\u001b[0m \u001b[39mexcept\u001b[39;00m _CONNECTION_ERROR_CLASSES \u001b[39mas\u001b[39;00m e:\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\resumable_media\\requests\\upload.py:149\u001b[0m, in \u001b[0;36mMultipartUpload.transmit.<locals>.retriable_request\u001b[1;34m()\u001b[0m\n",
      "\u001b[0;32m    145\u001b[0m result \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39mrequest(\n",
      "\u001b[0;32m    146\u001b[0m     method, url, data\u001b[39m=\u001b[39mpayload, headers\u001b[39m=\u001b[39mheaders, timeout\u001b[39m=\u001b[39mtimeout\n",
      "\u001b[0;32m    147\u001b[0m )\n",
      "\u001b[1;32m--> 149\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_response(result)\n",
      "\u001b[0;32m    151\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\resumable_media\\_upload.py:125\u001b[0m, in \u001b[0;36mUploadBase._process_response\u001b[1;34m(self, response)\u001b[0m\n",
      "\u001b[0;32m    124\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_finished \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;32m--> 125\u001b[0m _helpers\u001b[39m.\u001b[39;49mrequire_status_code(response, (http\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mOK,), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_status_code)\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\resumable_media\\_helpers.py:108\u001b[0m, in \u001b[0;36mrequire_status_code\u001b[1;34m(response, status_codes, get_status_code, callback)\u001b[0m\n",
      "\u001b[0;32m    107\u001b[0m         callback()\n",
      "\u001b[1;32m--> 108\u001b[0m     \u001b[39mraise\u001b[39;00m common\u001b[39m.\u001b[39mInvalidResponse(\n",
      "\u001b[0;32m    109\u001b[0m         response,\n",
      "\u001b[0;32m    110\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRequest failed with status code\u001b[39m\u001b[39m\"\u001b[39m,\n",
      "\u001b[0;32m    111\u001b[0m         status_code,\n",
      "\u001b[0;32m    112\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected one of\u001b[39m\u001b[39m\"\u001b[39m,\n",
      "\u001b[0;32m    113\u001b[0m         \u001b[39m*\u001b[39mstatus_codes\n",
      "\u001b[0;32m    114\u001b[0m     )\n",
      "\u001b[0;32m    115\u001b[0m \u001b[39mreturn\u001b[39;00m status_code\n",
      "\n",
      "\u001b[1;31mInvalidResponse\u001b[0m: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[1;31mBadRequest\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[64], line 5\u001b[0m\n",
      "\u001b[0;32m      3\u001b[0m carga_tabla_bq(dataset_id, \u001b[39m'\u001b[39m\u001b[39mfac_economico\u001b[39m\u001b[39m'\u001b[39m, bucket_name, project_id, \u001b[39m'\u001b[39m\u001b[39mid_fac_eco\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;32m      4\u001b[0m carga_tabla_bq(dataset_id, \u001b[39m'\u001b[39m\u001b[39minmigracion\u001b[39m\u001b[39m'\u001b[39m, bucket_name, project_id, \u001b[39m'\u001b[39m\u001b[39mid_inmigracion\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m----> 5\u001b[0m carga_tabla_bq(dataset_id, \u001b[39m'\u001b[39;49m\u001b[39mmigracion\u001b[39;49m\u001b[39m'\u001b[39;49m, bucket_name, project_id, \u001b[39m'\u001b[39;49m\u001b[39mid_migracion\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\n",
      "Cell \u001b[1;32mIn[63], line 39\u001b[0m, in \u001b[0;36mcarga_tabla_bq\u001b[1;34m(dataset_id, table_id, bucket, project_id, primary_key)\u001b[0m\n",
      "\u001b[0;32m     33\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m new_rows\u001b[39m.\u001b[39mempty:\n",
      "\u001b[0;32m     34\u001b[0m     job_config \u001b[39m=\u001b[39m bigquery\u001b[39m.\u001b[39mLoadJobConfig(\n",
      "\u001b[0;32m     35\u001b[0m         write_disposition\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWRITE_APPEND\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m# Append al final de la tabla\u001b[39;00m\n",
      "\u001b[0;32m     36\u001b[0m         autodetect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m# Detectar automáticamente el esquema de la tabla\u001b[39;00m\n",
      "\u001b[0;32m     37\u001b[0m     )\n",
      "\u001b[1;32m---> 39\u001b[0m     job \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mload_table_from_dataframe(new_rows, table_ref, job_config\u001b[39m=\u001b[39;49mjob_config)\n",
      "\u001b[0;32m     40\u001b[0m     job\u001b[39m.\u001b[39mresult()\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\cloud\\bigquery\\client.py:2734\u001b[0m, in \u001b[0;36mClient.load_table_from_dataframe\u001b[1;34m(self, dataframe, destination, num_retries, job_id, job_id_prefix, location, project, job_config, parquet_compression, timeout)\u001b[0m\n",
      "\u001b[0;32m   2732\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(tmppath, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m tmpfile:\n",
      "\u001b[0;32m   2733\u001b[0m         file_size \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mgetsize(tmppath)\n",
      "\u001b[1;32m-> 2734\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_table_from_file(\n",
      "\u001b[0;32m   2735\u001b[0m             tmpfile,\n",
      "\u001b[0;32m   2736\u001b[0m             destination,\n",
      "\u001b[0;32m   2737\u001b[0m             num_retries\u001b[39m=\u001b[39;49mnum_retries,\n",
      "\u001b[0;32m   2738\u001b[0m             rewind\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n",
      "\u001b[0;32m   2739\u001b[0m             size\u001b[39m=\u001b[39;49mfile_size,\n",
      "\u001b[0;32m   2740\u001b[0m             job_id\u001b[39m=\u001b[39;49mjob_id,\n",
      "\u001b[0;32m   2741\u001b[0m             job_id_prefix\u001b[39m=\u001b[39;49mjob_id_prefix,\n",
      "\u001b[0;32m   2742\u001b[0m             location\u001b[39m=\u001b[39;49mlocation,\n",
      "\u001b[0;32m   2743\u001b[0m             project\u001b[39m=\u001b[39;49mproject,\n",
      "\u001b[0;32m   2744\u001b[0m             job_config\u001b[39m=\u001b[39;49mnew_job_config,\n",
      "\u001b[0;32m   2745\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n",
      "\u001b[0;32m   2746\u001b[0m         )\n",
      "\u001b[0;32m   2748\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[0;32m   2749\u001b[0m     os\u001b[39m.\u001b[39mremove(tmppath)\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\cloud\\bigquery\\client.py:2490\u001b[0m, in \u001b[0;36mClient.load_table_from_file\u001b[1;34m(self, file_obj, destination, rewind, size, num_retries, job_id, job_id_prefix, location, project, job_config, timeout)\u001b[0m\n",
      "\u001b[0;32m   2486\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_multipart_upload(\n",
      "\u001b[0;32m   2487\u001b[0m             file_obj, job_resource, size, num_retries, timeout, project\u001b[39m=\u001b[39mproject\n",
      "\u001b[0;32m   2488\u001b[0m         )\n",
      "\u001b[0;32m   2489\u001b[0m \u001b[39mexcept\u001b[39;00m resumable_media\u001b[39m.\u001b[39mInvalidResponse \u001b[39mas\u001b[39;00m exc:\n",
      "\u001b[1;32m-> 2490\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_http_response(exc\u001b[39m.\u001b[39mresponse)\n",
      "\u001b[0;32m   2492\u001b[0m \u001b[39mreturn\u001b[39;00m typing\u001b[39m.\u001b[39mcast(LoadJob, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjob_from_resource(response\u001b[39m.\u001b[39mjson()))\n",
      "\n",
      "\u001b[1;31mBadRequest\u001b[0m: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/ethereal-accord-397414/jobs?uploadType=multipart: Provided Schema does not match Table ethereal-accord-397414:Migraciones.migracion. Field anio has changed type from DATE to STRING"
     ]
    }
   ],
   "source": [
    "# carga_tabla_bq(dataset_id, 'pais', bucket_name, project_id, 'id_pais')\n",
    "# carga_tabla_bq(dataset_id, 'fac_social', bucket_name, project_id, 'id_fac_soc')\n",
    "# carga_tabla_bq(dataset_id, 'fac_economico', bucket_name, project_id, 'id_fac_eco')\n",
    "# carga_tabla_bq(dataset_id, 'inmigracion', bucket_name, project_id, 'id_inmigracion')\n",
    "# carga_tabla_bq(dataset_id, 'migracion', bucket_name, project_id, 'id_migracion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def carga_tabla_bq(dataset_id, table_id, bucket):\n",
    "\n",
    "#     file_path = bq_folder_name + table_id + '.csv'\n",
    "#     cloud_storage_uri = f'gs://{bucket}/{file_path}'\n",
    "#     client = bigquery.Client()\n",
    "\n",
    "#     # Define el ID completo de la tabla en BigQuery\n",
    "#     table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "#     # Configura la carga de datos\n",
    "#     job_config = bigquery.LoadJobConfig(\n",
    "#         autodetect=True,  # Detectar automáticamente el esquema de la tabla\n",
    "#         skip_leading_rows=1,  # Si tu archivo CSV tiene una fila de encabezado\n",
    "#         source_format=bigquery.SourceFormat.CSV,  # Formato del archivo CSV\n",
    "#         # write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "#     )\n",
    "\n",
    "#     # Carga los datos desde el archivo CSV en Cloud Storage a la tabla en BigQuery\n",
    "#     load_job = client.load_table_from_uri(\n",
    "#         cloud_storage_uri, table_ref, job_config=job_config\n",
    "#     )\n",
    "\n",
    "#     # Espera a que se complete la carga del trabajo\n",
    "#     load_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargas hacia Big Query\n",
    "# carga_tabla_bq(dataset_id, 'pais', bucket_name)\n",
    "# carga_tabla_bq(dataset_id, 'migracion', bucket_name)\n",
    "# carga_tabla_bq(dataset_id, 'inmigracion', bucket_name)\n",
    "# carga_tabla_bq(dataset_id, 'fac_social', bucket_name)\n",
    "# carga_tabla_bq(dataset_id, 'fac_economico', bucket_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
