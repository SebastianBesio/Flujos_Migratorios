{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"ethereal-accord-397414-944cb605214b.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creción de Tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_tabla(dataset_id, table_id, schema):\n",
    "    \"\"\"\n",
    "    Funcion que crea una tabla en el dataset con el schema pasado.\n",
    "    \"\"\"\n",
    "    client = bigquery.Client()\n",
    "    # Preparar estructura de la tabla.\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    table = bigquery.Table(table_ref, schema=schema)\n",
    "\n",
    "    # Envía la solicitud para crear la tabla.\n",
    "    client.create_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir nombre del Dataset\n",
    "dataset_id = \"Migraciones\"\n",
    "project_id = \"ethereal-accord-397414\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "File ethereal-accord-397414-944cb605214b.json was not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      2\u001b[0m table_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpais\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m schema \u001b[39m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m     bigquery\u001b[39m.\u001b[39mSchemaField(\u001b[39m\"\u001b[39m\u001b[39mid_pais\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mINTEGER\u001b[39m\u001b[39m\"\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNULLABLE\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m      6\u001b[0m     bigquery\u001b[39m.\u001b[39mSchemaField(\u001b[39m\"\u001b[39m\u001b[39mnombre\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSTRING\u001b[39m\u001b[39m\"\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNULLABLE\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m ]\n\u001b[1;32m----> 9\u001b[0m crear_tabla(dataset_id, table_id, schema)\n",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m, in \u001b[0;36mcrear_tabla\u001b[1;34m(dataset_id, table_id, schema)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcrear_tabla\u001b[39m(dataset_id, table_id, schema):\n\u001b[0;32m      2\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m    Funcion que crea una tabla en el dataset con el schema pasado.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     client \u001b[39m=\u001b[39m bigquery\u001b[39m.\u001b[39;49mClient()\n\u001b[0;32m      6\u001b[0m     \u001b[39m# Preparar estructura de la tabla.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     table_ref \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mdataset(dataset_id)\u001b[39m.\u001b[39mtable(table_id)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\cloud\\bigquery\\client.py:245\u001b[0m, in \u001b[0;36mClient.__init__\u001b[1;34m(self, project, credentials, _http, location, default_query_job_config, default_load_job_config, client_info, client_options)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    235\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    236\u001b[0m     project\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    243\u001b[0m     client_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    244\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 245\u001b[0m     \u001b[39msuper\u001b[39;49m(Client, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    246\u001b[0m         project\u001b[39m=\u001b[39;49mproject,\n\u001b[0;32m    247\u001b[0m         credentials\u001b[39m=\u001b[39;49mcredentials,\n\u001b[0;32m    248\u001b[0m         client_options\u001b[39m=\u001b[39;49mclient_options,\n\u001b[0;32m    249\u001b[0m         _http\u001b[39m=\u001b[39;49m_http,\n\u001b[0;32m    250\u001b[0m     )\n\u001b[0;32m    252\u001b[0m     kw_args \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mclient_info\u001b[39m\u001b[39m\"\u001b[39m: client_info}\n\u001b[0;32m    253\u001b[0m     bq_host \u001b[39m=\u001b[39m _get_bigquery_host()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\cloud\\client\\__init__.py:320\u001b[0m, in \u001b[0;36mClientWithProject.__init__\u001b[1;34m(self, project, credentials, client_options, _http)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, project\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, credentials\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, client_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, _http\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 320\u001b[0m     _ClientProjectMixin\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, project\u001b[39m=\u001b[39;49mproject, credentials\u001b[39m=\u001b[39;49mcredentials)\n\u001b[0;32m    321\u001b[0m     Client\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m    322\u001b[0m         \u001b[39mself\u001b[39m, credentials\u001b[39m=\u001b[39mcredentials, client_options\u001b[39m=\u001b[39mclient_options, _http\u001b[39m=\u001b[39m_http\n\u001b[0;32m    323\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\cloud\\client\\__init__.py:268\u001b[0m, in \u001b[0;36m_ClientProjectMixin.__init__\u001b[1;34m(self, project, credentials)\u001b[0m\n\u001b[0;32m    265\u001b[0m     project \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(credentials, \u001b[39m\"\u001b[39m\u001b[39mproject_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    267\u001b[0m \u001b[39mif\u001b[39;00m project \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 268\u001b[0m     project \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_determine_default(project)\n\u001b[0;32m    270\u001b[0m \u001b[39mif\u001b[39;00m project \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    272\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mProject was not passed and could not be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdetermined from the environment.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\cloud\\client\\__init__.py:287\u001b[0m, in \u001b[0;36m_ClientProjectMixin._determine_default\u001b[1;34m(project)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    285\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_determine_default\u001b[39m(project):\n\u001b[0;32m    286\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Helper:  use default project detection.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     \u001b[39mreturn\u001b[39;00m _determine_default_project(project)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\cloud\\_helpers\\__init__.py:152\u001b[0m, in \u001b[0;36m_determine_default_project\u001b[1;34m(project)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Determine default project ID explicitly or implicitly as fall-back.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \n\u001b[0;32m    142\u001b[0m \u001b[39mSee :func:`google.auth.default` for details on how the default project\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[39m:returns: Default project if it can be determined.\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[39mif\u001b[39;00m project \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 152\u001b[0m     _, project \u001b[39m=\u001b[39m google\u001b[39m.\u001b[39;49mauth\u001b[39m.\u001b[39;49mdefault()\n\u001b[0;32m    153\u001b[0m \u001b[39mreturn\u001b[39;00m project\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\auth\\_default.py:659\u001b[0m, in \u001b[0;36mdefault\u001b[1;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[0;32m    647\u001b[0m checkers \u001b[39m=\u001b[39m (\n\u001b[0;32m    648\u001b[0m     \u001b[39m# Avoid passing scopes here to prevent passing scopes to user credentials.\u001b[39;00m\n\u001b[0;32m    649\u001b[0m     \u001b[39m# with_scopes_if_required() below will ensure scopes/default scopes are\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[39mlambda\u001b[39;00m: _get_gce_credentials(request, quota_project_id\u001b[39m=\u001b[39mquota_project_id),\n\u001b[0;32m    656\u001b[0m )\n\u001b[0;32m    658\u001b[0m \u001b[39mfor\u001b[39;00m checker \u001b[39min\u001b[39;00m checkers:\n\u001b[1;32m--> 659\u001b[0m     credentials, project_id \u001b[39m=\u001b[39m checker()\n\u001b[0;32m    660\u001b[0m     \u001b[39mif\u001b[39;00m credentials \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m         credentials \u001b[39m=\u001b[39m with_scopes_if_required(\n\u001b[0;32m    662\u001b[0m             credentials, scopes, default_scopes\u001b[39m=\u001b[39mdefault_scopes\n\u001b[0;32m    663\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\auth\\_default.py:652\u001b[0m, in \u001b[0;36mdefault.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauth\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcredentials\u001b[39;00m \u001b[39mimport\u001b[39;00m CredentialsWithQuotaProject\n\u001b[0;32m    643\u001b[0m explicit_project_id \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\n\u001b[0;32m    644\u001b[0m     environment_vars\u001b[39m.\u001b[39mPROJECT, os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(environment_vars\u001b[39m.\u001b[39mLEGACY_PROJECT)\n\u001b[0;32m    645\u001b[0m )\n\u001b[0;32m    647\u001b[0m checkers \u001b[39m=\u001b[39m (\n\u001b[0;32m    648\u001b[0m     \u001b[39m# Avoid passing scopes here to prevent passing scopes to user credentials.\u001b[39;00m\n\u001b[0;32m    649\u001b[0m     \u001b[39m# with_scopes_if_required() below will ensure scopes/default scopes are\u001b[39;00m\n\u001b[0;32m    650\u001b[0m     \u001b[39m# safely set on the returned credentials since requires_scopes will\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[39m# guard against setting scopes on user credentials.\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m     \u001b[39mlambda\u001b[39;00m: _get_explicit_environ_credentials(quota_project_id\u001b[39m=\u001b[39;49mquota_project_id),\n\u001b[0;32m    653\u001b[0m     \u001b[39mlambda\u001b[39;00m: _get_gcloud_sdk_credentials(quota_project_id\u001b[39m=\u001b[39mquota_project_id),\n\u001b[0;32m    654\u001b[0m     _get_gae_credentials,\n\u001b[0;32m    655\u001b[0m     \u001b[39mlambda\u001b[39;00m: _get_gce_credentials(request, quota_project_id\u001b[39m=\u001b[39mquota_project_id),\n\u001b[0;32m    656\u001b[0m )\n\u001b[0;32m    658\u001b[0m \u001b[39mfor\u001b[39;00m checker \u001b[39min\u001b[39;00m checkers:\n\u001b[0;32m    659\u001b[0m     credentials, project_id \u001b[39m=\u001b[39m checker()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\auth\\_default.py:272\u001b[0m, in \u001b[0;36m_get_explicit_environ_credentials\u001b[1;34m(quota_project_id)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_gcloud_sdk_credentials(quota_project_id\u001b[39m=\u001b[39mquota_project_id)\n\u001b[0;32m    271\u001b[0m \u001b[39mif\u001b[39;00m explicit_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m     credentials, project_id \u001b[39m=\u001b[39m load_credentials_from_file(\n\u001b[0;32m    273\u001b[0m         os\u001b[39m.\u001b[39;49menviron[environment_vars\u001b[39m.\u001b[39;49mCREDENTIALS], quota_project_id\u001b[39m=\u001b[39;49mquota_project_id\n\u001b[0;32m    274\u001b[0m     )\n\u001b[0;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m credentials, project_id\n\u001b[0;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\auth\\_default.py:116\u001b[0m, in \u001b[0;36mload_credentials_from_file\u001b[1;34m(filename, scopes, default_scopes, quota_project_id, request)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Loads Google credentials from a file.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \n\u001b[0;32m     86\u001b[0m \u001b[39mThe credentials file must be a service account key, stored authorized\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39m        wrong format or is missing.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(filename):\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mDefaultCredentialsError(\n\u001b[0;32m    117\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m was not found.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(filename)\n\u001b[0;32m    118\u001b[0m     )\n\u001b[0;32m    120\u001b[0m \u001b[39mwith\u001b[39;00m io\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file_obj:\n\u001b[0;32m    121\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m: File ethereal-accord-397414-944cb605214b.json was not found."
     ]
    }
   ],
   "source": [
    "# Crear tabla 'pais'\n",
    "table_id = \"pais\"\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"id_pais\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"nombre\", \"STRING\", mode=\"NULLABLE\")\n",
    "]\n",
    "\n",
    "crear_tabla(dataset_id, table_id, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla 'fac_social'\n",
    "table_id = \"fac_social\"\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"id_fac_soc\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"hdi\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"anio_prom_esc\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"esperanza_vida\", \"FLOAT\", mode=\"NULLABLE\")\n",
    "]\n",
    "\n",
    "crear_tabla(dataset_id, table_id, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla 'inmigracion'\n",
    "table_id = \"inmigracion\"\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"id_inmigracion\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"hombres\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"mujeres\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"total\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Argentina\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Antigua_y_Barbuda\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Bahamas\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Belice\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Bolivia\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Brasil\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Canada\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Chile\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Colombia\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Costa_Rica\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Cuba\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Santa_Lucia\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Ecuador\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Granada\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Guatemala\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Guyana\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Honduras\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Haiti\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Jamaica\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Republica_Dominicana\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Mexico\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Nicaragua\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Panama\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Peru\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Paraguay\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"El_Salvador\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Trinidad_y_Tobago\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Uruguay\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Estados_Unidos\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Venezuela\", \"INTEGER\", mode=\"NULLABLE\")\n",
    "]\n",
    "\n",
    "crear_tabla(dataset_id, table_id, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla 'fac_economico'\n",
    "table_id = \"fac_economico\"\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"id_fac_eco\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"pbi_per_capita\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"pbi_per_cap_aj\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"desempleo\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "]\n",
    "\n",
    "crear_tabla(dataset_id, table_id, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla 'migracion'\n",
    "table_id = \"migracion\"\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"id_migracion\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"id_inmigracion\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"id_fac_soc\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"id_fac_eco\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"id_pais\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"migracion_neta\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"migracion_neta_pred\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"anio\", \"DATE\", mode=\"NULLABLE\"),\n",
    "]\n",
    "\n",
    "crear_tabla(dataset_id, table_id, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################\n",
    "# Generacion Data Frames preparados para BigQuery  y guardado CSV respaldo en el Cloud Storage\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder_name = \"ArchivosFuente/\"\n",
    "bq_folder_name = \"ParaBigQuery/\"\n",
    "bucket_name = 'bucket-pf-flujos_migratorios'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lectura_csv_bucket(file_path, bucket_name):\n",
    "    \"\"\" \n",
    "    Lectura de un csv en file_path desde el Bucket bucket_name.\n",
    "    Retorna un DataFrame con el csv leido.\n",
    "    \"\"\"\n",
    "    # Crea un cliente de almacenamiento de Google Cloud\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Obtiene el cubo de almacenamiento\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    # Obtiene el objeto de archivo CSV\n",
    "    blob = bucket.blob(file_path)\n",
    "\n",
    "    # Lee el contenido del archivo CSV en un DataFrame de Pandas\n",
    "    with blob.open(\"r\") as file:\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def guardado_csv_bucket(df, file_path, bucket_name):\n",
    "    \"\"\" \n",
    "    Guardado de un DataFrame en csv en file_path desde el Bucket bucket_name.\n",
    "    \"\"\"\n",
    "    # Guarda el DataFrame en un archivo CSV\n",
    "    csv_data = df.to_csv(index=False)\n",
    "\n",
    "    # Crea un cliente de almacenamiento de Google Cloud\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Obtiene el cubo de almacenamiento\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    # Carga el archivo CSV en el bucket de Google Cloud Storage\n",
    "    blob = bucket.blob(file_path)\n",
    "    blob.upload_from_string(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de todos los csv fuentes desde el Bucket.\n",
    "file_path_undp = source_folder_name + 'migracion_undp.csv'\n",
    "df_undp = lectura_csv_bucket(file_path_undp, bucket_name)\n",
    "file_path_bm = source_folder_name + 'migracion_desempleo_pbi_per_capita.csv'\n",
    "df_bm = lectura_csv_bucket(file_path_bm, bucket_name)\n",
    "file_path_inmigracion = source_folder_name + 'Inmigracion_por_pais.csv'\n",
    "df_inmigracion = lectura_csv_bucket(file_path_inmigracion, bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Generacion DF y CSV para tabla 'pais'\n",
    "######################################\n",
    "\n",
    "# Generador de 'id_pais'\n",
    "pais = []\n",
    "j = 1\n",
    "for i in (df_undp['Pais'].unique()):\n",
    "    pais.append([j,i])\n",
    "    j += 1\n",
    "\n",
    "df_bq_pais = pd.DataFrame(pais, columns = ['id_pais','nombre'])\n",
    "\n",
    "# Guardo CSV\n",
    "file_path = bq_folder_name + 'pais.csv'\n",
    "guardado_csv_bucket(df_bq_pais, file_path, bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Generacion DF y CSV para tabla 'fac_social'\n",
    "######################################\n",
    "\n",
    "# Como son todos del mismo Dataset no necesitamos hacer un merge.\n",
    "df_bq_fac_soc = df_undp.copy()\n",
    "df_bq_fac_soc['id_pais'] = df_undp['Pais'].replace(dict(zip(df_bq_pais[\"nombre\"], df_bq_pais[\"id_pais\"])))\n",
    "df_bq_fac_soc['id_fac_soc'] = 10000 * df_bq_fac_soc['Anio'] + df_bq_fac_soc['id_pais']\n",
    "\n",
    "df_bq_fac_soc.drop(columns=['Pais', 'id_pais', 'Anio', 'PBI_per_cap_aj'], inplace=True)\n",
    "\n",
    "df_bq_fac_soc.head()\n",
    "\n",
    "# Guardo CSV\n",
    "file_path = bq_folder_name + 'fac_social.csv'\n",
    "guardado_csv_bucket(df_bq_fac_soc, file_path, bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Generacion DF y CSV para tabla 'fac_economico'\n",
    "######################################\n",
    "\n",
    "df_bq_fac_eco = df_undp.merge(df_bm, on=['Pais', 'Anio'])\n",
    "\n",
    "df_bq_fac_eco['id_pais'] = df_bq_fac_eco['Pais'].replace(dict(zip(df_bq_pais[\"nombre\"], df_bq_pais[\"id_pais\"])))\n",
    "df_bq_fac_eco['id_fac_eco'] = 10000 * df_bq_fac_eco['Anio'] + df_bq_fac_eco['id_pais']\n",
    "\n",
    "df_bq_fac_eco.drop(columns=['Pais', 'id_pais', 'Anio', 'hdi', 'Esperanza_vida', 'Anio_prom_esc', 'migracion_neta'], inplace=True)\n",
    "\n",
    "df_bq_fac_eco.rename(columns={'PBI_per_cap_aj': 'pbi_per_cap_aj'}, inplace=True)\n",
    "\n",
    "# Guardo CSV\n",
    "file_path = bq_folder_name + 'fac_economico.csv'\n",
    "guardado_csv_bucket(df_bq_fac_eco, file_path, bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Generacion DF y CSV para tabla 'inmigracion'\n",
    "######################################\n",
    "\n",
    "df_bq_inmigracion = df_inmigracion.copy()\n",
    "df_bq_inmigracion['id_pais'] = df_bq_inmigracion['Pais'].replace(dict(zip(df_bq_pais[\"nombre\"], df_bq_pais[\"id_pais\"])))\n",
    "df_bq_inmigracion['id_inmigracion'] = 10000 * df_bq_inmigracion['Anio'] + df_bq_inmigracion['id_pais']\n",
    "\n",
    "df_bq_inmigracion.drop(columns=['Pais', 'id_pais', 'Anio'], inplace=True)\n",
    "# Renombro asi coinciden\n",
    "df_bq_inmigracion.rename(columns={'Inmigrantes_hombres': 'hombres', 'Inmigrantes_mujeres': 'mujeres', 'Inmigrantes': 'total'}, inplace=True)\n",
    "\n",
    "# Paso a Int\n",
    "df_bq_inmigracion[df_bq_inmigracion.columns] = df_bq_inmigracion[df_bq_inmigracion.columns].astype('Int64')\n",
    "\n",
    "# Guardo CSV\n",
    "file_path = bq_folder_name + 'inmigracion.csv'\n",
    "guardado_csv_bucket(df_bq_inmigracion, file_path, bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Generacion DF y CSV para tabla 'migracion'\n",
    "######################################\n",
    "\n",
    "df_bq_migracion = df_bm.copy()\n",
    "df_bq_migracion['id_pais'] = df_bq_migracion['Pais'].replace(dict(zip(df_bq_pais[\"nombre\"], df_bq_pais[\"id_pais\"])))\n",
    "df_bq_migracion['id_migracion'] = 10000 * df_bq_migracion['Anio'] + df_bq_migracion['id_pais']\n",
    "\n",
    "df_bq_migracion.drop(columns=['Pais', 'desempleo', 'pbi_per_capita'], inplace=True)\n",
    "# Anio con minuscula\n",
    "df_bq_migracion.rename(columns={'Anio': 'anio'}, inplace=True)\n",
    "\n",
    "# crear ids de los otros copiando de id_migracion\n",
    "df_bq_migracion['id_inmigracion'] = df_bq_migracion['id_migracion']\n",
    "df_bq_migracion['id_fac_soc'] = df_bq_migracion['id_migracion']\n",
    "df_bq_migracion['id_fac_eco'] = df_bq_migracion['id_migracion']\n",
    "\n",
    "#Quitar id erroneos\n",
    "df_bq_migracion.loc[~df_bq_migracion['id_migracion'].isin(df_bq_inmigracion['id_inmigracion']), 'id_inmigracion'] = None\n",
    "df_bq_migracion.loc[~df_bq_migracion['id_migracion'].isin(df_bq_fac_soc['id_fac_soc']), 'id_fac_soc'] = None\n",
    "df_bq_migracion.loc[~df_bq_migracion['id_migracion'].isin(df_bq_fac_eco['id_fac_eco']), 'id_fac_eco'] = None\n",
    "\n",
    "# Vuelvo a convertir a Int\n",
    "df_bq_migracion['id_inmigracion'] = df_bq_migracion['id_inmigracion'].astype('Int64')\n",
    "df_bq_migracion['id_fac_soc'] = df_bq_migracion['id_fac_soc'].astype('Int64')\n",
    "df_bq_migracion['id_fac_eco'] = df_bq_migracion['id_fac_eco'].astype('Int64')\n",
    "df_bq_migracion['migracion_neta'] = df_bq_migracion['migracion_neta'].astype('Int64')\n",
    "\n",
    "# Convertir anio a tipo DATE\n",
    "df_bq_migracion['anio'] = df_bq_migracion['anio'].astype(\"string\") + \"-01-01\"\n",
    "df_bq_migracion['anio'] =  pd.to_datetime(df_bq_migracion['anio'], format=\"%Y-%m-%d\")\n",
    "\n",
    "# Guardo CSV\n",
    "file_path = bq_folder_name + 'migracion.csv'\n",
    "guardado_csv_bucket(df_bq_migracion, file_path, bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################################\n",
    "# Pasaje a BigQuery\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carga_tabla_bq(df, dataset_id, table_id, bucket, project_id, primary_key):\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # Define el ID completo de la tabla en BigQuery\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "    # Query existing data from the table\n",
    "    query = f\"SELECT {primary_key} FROM `{project_id}.{dataset_id}.{table_id}`\"\n",
    "    existing_primary_keys = set(row[primary_key] for row in client.query(query))\n",
    "\n",
    "    # Identify unique rows based on primary key\n",
    "    new_rows = df[~df[primary_key].isin(existing_primary_keys)]\n",
    "    \n",
    "    print(new_rows)\n",
    "    \n",
    "    # Load the new rows into BigQuery\n",
    "    if not new_rows.empty:\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            write_disposition=\"WRITE_APPEND\", # Append al final de la tabla\n",
    "            autodetect=True, # Detectar automáticamente el esquema de la tabla\n",
    "        )\n",
    "\n",
    "        job = client.load_table_from_dataframe(new_rows, table_ref, job_config=job_config)\n",
    "        job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id_pais, nombre]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [hdi, Esperanza_vida, Anio_prom_esc, id_fac_soc]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [pbi_per_cap_aj, desempleo, pbi_per_capita, id_fac_eco]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [hombres, mujeres, total, Argentina, Antigua_y_Barbuda, Bahamas, Belice, Bolivia, Brasil, Canada, Chile, Colombia, Costa_Rica, Cuba, Santa_Lucia, Ecuador, Granada, Guatemala, Guyana, Honduras, Haiti, Jamaica, Republica_Dominicana, Mexico, Nicaragua, Panama, Peru, Paraguay, El_Salvador, Trinidad_y_Tobago, Uruguay, Estados_Unidos, Venezuela, id_inmigracion]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 34 columns]\n",
      "Empty DataFrame\n",
      "Columns: [anio, migracion_neta, id_pais, id_migracion, id_inmigracion, id_fac_soc, id_fac_eco]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "carga_tabla_bq(df_bq_pais, dataset_id, 'pais', bucket_name, project_id, 'id_pais')\n",
    "carga_tabla_bq(df_bq_fac_soc, dataset_id, 'fac_social', bucket_name, project_id, 'id_fac_soc')\n",
    "carga_tabla_bq(df_bq_fac_eco, dataset_id, 'fac_economico', bucket_name, project_id, 'id_fac_eco')\n",
    "carga_tabla_bq(df_bq_inmigracion, dataset_id, 'inmigracion', bucket_name, project_id, 'id_inmigracion')\n",
    "carga_tabla_bq(df_bq_migracion, dataset_id, 'migracion', bucket_name, project_id, 'id_migracion')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
